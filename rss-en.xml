<?xml version='1.0' encoding='UTF-8'?>
<?xml-stylesheet type="text/xsl" href="rss-style.xsl"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>Hacker News - English</title>
    <link>https://tang1keke.github.io/hn-summary-and-translate</link>
    <description>Hacker News articles summarized and translated to English</description>
    <language>en</language>
    <lastBuildDate>Fri, 21 Nov 2025 09:25:21 +0000</lastBuildDate>
    <generator>HN RSS Translator</generator>
    <atom:link rel="self" type="application/rss+xml" href="https://tang1keke.github.io/hn-summary-and-translate/rss-en.xml"/>
    <item>
      <title>Olmo 3: Charting a path through the model flow to lead open-source AI</title>
      <link>https://allenai.org/blog/olmo3</link>
      <description>&lt;p&gt;Olmo 3-Base (7B, 32B) is our most powerful base model yet. Olmo 3-Think (7B, 32B) is our flagship post-trained reasoning set built on Olmo 3-Base. Olmo 3-Instruct (7B) is a chat and quick-response focused post-train of Olmo 3-Base that handles multi-turn, instruction-following, tool use, and more.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46001889"&gt;&lt;strong&gt;HN Discussion&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href='https://allenai.org/blog/olmo3'&gt;Read Original Article&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Top 6 Comments:&lt;/strong&gt;&lt;/p&gt;
&lt;div style="margin: 10px 0; padding: 10px; background: #f6f6f6; border-left: 3px solid #ff6600;"&gt;&lt;p style="margin: 0 0 5px 0;"&gt;&lt;strong&gt;josephcooney:&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin: 0;"&gt;The trace is interesting. The training cut-off according to the model is nearly a year old though.&lt;/p&gt;&lt;/div&gt;
&lt;div style="margin: 10px 0; padding: 10px; background: #f6f6f6; border-left: 3px solid #ff6600;"&gt;&lt;p style="margin: 0 0 5px 0;"&gt;&lt;strong&gt;thot_experiment:&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin: 0;"&gt;Qwen3-30B-VL is going to be fucking hard to beat as a daily driver, it&amp;#x27;s so good for the base 80% of tasks I want an AI for, and holy fuck is it fast. 90tok&amp;#x2F;s on my machine, I pretty much keep it in vram permanently. I think this sort of work is important and I&amp;#x27;m really glad it&amp;#x27;s being done, but in terms of something I want to use every day there&amp;#x27;s no way a dense model can compete unless it&amp;#x27;s smart as fuck. Even dumb models like Qwen3-30B get a lot of stuff right and not having to wait is amazing.&lt;/p&gt;&lt;/div&gt;
&lt;div style="margin: 10px 0; padding: 10px; background: #f6f6f6; border-left: 3px solid #ff6600;"&gt;&lt;p style="margin: 0 0 5px 0;"&gt;&lt;strong&gt;fragmede:&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin: 0;"&gt;Clear pak LLMs are rare. The term open source has become co-opted, so I think we need a new term for LLMs who&amp;#x27;s alignment is known.&lt;/p&gt;&lt;/div&gt;
&lt;div style="margin: 10px 0; padding: 10px; background: #f6f6f6; border-left: 3px solid #ff6600;"&gt;&lt;p style="margin: 0 0 5px 0;"&gt;&lt;strong&gt;krzysiek:&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin: 0;"&gt;To see OlmoTrace go to &lt;a href="https:&amp;#x2F;&amp;#x2F;playground.allenai.org&amp;#x2F;" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;playground.allenai.org&amp;#x2F;&lt;/a&gt; and after you get the responce to your prompt, click the secod icon from the right on the top (at least on mobile). It took me a while to find it because there is another icon under the responce that looks the same but does something else.&lt;/p&gt;&lt;/div&gt;
&lt;div style="margin: 10px 0; padding: 10px; background: #f6f6f6; border-left: 3px solid #ff6600;"&gt;&lt;p style="margin: 0 0 5px 0;"&gt;&lt;strong&gt;spiderfarmer:&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin: 0;"&gt;These small models are very cheap for &amp;quot;good enough&amp;quot; translations. I just translated 6M comments on my platform with Gemma 32B and this model seems to be on par.&lt;p&gt;It&amp;#x27;s cheap enough that I&amp;#x27;m currently doing a second pass where another model critiques and if needed, rewrites the original translation.&lt;/p&gt;&lt;/div&gt;
&lt;div style="margin: 10px 0; padding: 10px; background: #f6f6f6; border-left: 3px solid #ff6600;"&gt;&lt;p style="margin: 0 0 5px 0;"&gt;&lt;strong&gt;stavros:&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin: 0;"&gt;&amp;gt; the best fully open 32B-scale thinking model&lt;p&gt;It&amp;#x27;s absolutely fantastic that they&amp;#x27;re releasing an actually OSS model, but isn&amp;#x27;t &amp;quot;the best fully open&amp;quot; a bit of a low bar? I&amp;#x27;m not aware of any other fully open models.&lt;/p&gt;&lt;/div&gt;</description>
      <guid isPermaLink="true">https://allenai.org/blog/olmo3</guid>
      <pubDate>Fri, 21 Nov 2025 06:50:14 +0000</pubDate>
      <comments>https://news.ycombinator.com/item?id=46001889</comments>
    </item>
    <item>
      <title>It's Hard to Build an Oscillator</title>
      <link>https://lcamtuf.substack.com/p/its-hard-to-build-an-oscillator</link>
      <guid isPermaLink="true">https://lcamtuf.substack.com/p/its-hard-to-build-an-oscillator</guid>
      <pubDate>Fri, 21 Nov 2025 07:45:53 +0000</pubDate>
      <comments>https://news.ycombinator.com/item?id=46002161</comments>
    </item>
  </channel>
</rss>
