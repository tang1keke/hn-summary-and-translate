<?xml version='1.0' encoding='UTF-8'?>
<?xml-stylesheet type="text/xsl" href="rss-style.xsl"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>Hacker News - English</title>
    <link>https://tang1keke.github.io/hn-summary-and-translate</link>
    <description>Hacker News articles summarized and translated to English</description>
    <language>en</language>
    <lastBuildDate>Wed, 19 Nov 2025 12:50:08 +0000</lastBuildDate>
    <generator>HN RSS Translator</generator>
    <atom:link rel="self" type="application/rss+xml" href="https://tang1keke.github.io/hn-summary-and-translate/rss-en.xml"/>
    <item>
      <title>Multimodal Diffusion Language Models for Thinking-Aware Editing and Generation</title>
      <link>https://github.com/tyfeld/MMaDA-Parallel</link>
      <description>&lt;p&gt;Environment Setup First, start with a torch environment with torch 2. MMaDA-Parallel-A is trained with tokenizer Amused-VQ, and MMaDA-Parallel-M is trained with tokenizer Magvitv2. Parallel Gen with MMaDA-Parallel-M cd MMaDA-Parallel-M python inference.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=45977542"&gt;&lt;strong&gt;HN Discussion&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href='https://github.com/tyfeld/MMaDA-Parallel'&gt;Read Original Article&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Top 3 Comments:&lt;/strong&gt;&lt;/p&gt;
&lt;div style="margin: 10px 0; padding: 10px; background: #f6f6f6; border-left: 3px solid #ff6600;"&gt;&lt;p style="margin: 0 0 5px 0;"&gt;&lt;strong&gt;boriskourt:&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin: 0;"&gt;Interesting approach and a very readable paper.&lt;p&gt;&amp;gt; We provide two varients of MMaDA-Parallel with different tokenizers. MMaDA-Parallel-A is trained with tokenizer Amused-VQ, and MMaDA-Parallel-M is trained with tokenizer Magvitv2.&lt;p&gt;tyfeld&amp;#x2F;MMaDA-Parallel-A: &lt;a href="https:&amp;#x2F;&amp;#x2F;huggingface.co&amp;#x2F;tyfeld&amp;#x2F;MMaDA-Parallel-A&amp;#x2F;tree&amp;#x2F;main" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;huggingface.co&amp;#x2F;tyfeld&amp;#x2F;MMaDA-Parallel-A&amp;#x2F;tree&amp;#x2F;main&lt;/a&gt;&lt;p&gt;tyfeld&amp;#x2F;MMaDA-Parallel-M: &lt;a href="https:&amp;#x2F;&amp;#x2F;huggingface.co&amp;#x2F;tyfeld&amp;#x2F;MMaDA-Parallel-M&amp;#x2F;tree&amp;#x2F;main" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;huggingface.co&amp;#x2F;tyfeld&amp;#x2F;MMaDA-Parallel-M&amp;#x2F;tree&amp;#x2F;main&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;
&lt;div style="margin: 10px 0; padding: 10px; background: #f6f6f6; border-left: 3px solid #ff6600;"&gt;&lt;p style="margin: 0 0 5px 0;"&gt;&lt;strong&gt;NitpickLawyer:&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin: 0;"&gt;&amp;gt; To resolve this, we propose a parallel multimodal diffusion framework, MMaDA-Parallel, that enables &lt;i&gt;continuous, bidirectional interaction&lt;/i&gt; between text and images throughout the entire denoising trajectory.&lt;p&gt;&amp;gt; (ParaRL), a novel strategy that applies &lt;i&gt;semantic rewards along the trajectory&lt;/i&gt; to enforce cross-modal consistency.&lt;p&gt;(emphasis mine)&lt;p&gt;This sounds really cool. The fact that one generation &amp;quot;attends&amp;quot; to the other is really interesting. I&amp;#x27;m curious if this would hold for other modalities. I&amp;#x27;m thinking coding specific applications, where things can change once something is generated. My hunch is that coding would benefit a lot from this approach, because the &amp;quot;manual&amp;quot; way of writing code often resembles diffusion more than autoregressive (that is, we often edit something here, then because we did that we have to import something, then change something there, then that leads to further changes, etc).&lt;p&gt;For now coding seems to benefit a lot from &amp;lt;thinking&amp;gt; -&amp;gt; &amp;lt;coding&amp;gt; -&amp;gt; &amp;lt;env_feedback&amp;gt; -&amp;gt; &amp;lt;reflexion&amp;gt; -&amp;gt; &amp;lt;thinking&amp;gt; -&amp;gt; &amp;lt;coding&amp;gt;, but this seems at a glance to be shoehorned in for autoregressive generation... GPT5 in particular seems to be better at this, with multiple &amp;quot;tool calls&amp;quot; interleaved in its thinking sessions. I wonder if this would get better with the paralel denoising thing proposed here, where both thinking and coding are done in paralel, and one can &amp;quot;attend&amp;quot; to the other. Add some feedback (linters, compilers, LSPs, tests, etc.) and this can go places. If it works.&lt;/p&gt;&lt;/div&gt;
&lt;div style="margin: 10px 0; padding: 10px; background: #f6f6f6; border-left: 3px solid #ff6600;"&gt;&lt;p style="margin: 0 0 5px 0;"&gt;&lt;strong&gt;Hard_Space:&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin: 0;"&gt;Be aware that the project page has the wrong Arxiv link at the time of writing. This is the correct one:&lt;p&gt;&lt;a href="https:&amp;#x2F;&amp;#x2F;arxiv.org&amp;#x2F;abs&amp;#x2F;2511.09611" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;arxiv.org&amp;#x2F;abs&amp;#x2F;2511.09611&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <guid isPermaLink="true">https://github.com/tyfeld/MMaDA-Parallel</guid>
      <pubDate>Wed, 19 Nov 2025 09:27:17 +0000</pubDate>
      <comments>https://news.ycombinator.com/item?id=45977542</comments>
    </item>
    <item>
      <title>Pimped Amiga 500</title>
      <link>https://www.pimyretro.org/pimped-amiga-500/</link>
      <description>&lt;p&gt;Back in the early ’90s, I had an Amiga 2000 with just one expansion card: a SCSI controller paired with a massive 290 MB hard drive. Wait a second — this is an Amiga 500, not a 500+. This means my A500 must have been modified to convert the slow RAM into chip RAM.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=45978545"&gt;&lt;strong&gt;HN Discussion&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href='https://www.pimyretro.org/pimped-amiga-500/'&gt;Read Original Article&lt;/a&gt;&lt;/p&gt;</description>
      <guid isPermaLink="true">https://www.pimyretro.org/pimped-amiga-500/</guid>
      <pubDate>Wed, 19 Nov 2025 12:02:49 +0000</pubDate>
      <comments>https://news.ycombinator.com/item?id=45978545</comments>
    </item>
    <item>
      <title>Klarna says AI drive has helped halve staff numbers and boost pay</title>
      <link>https://www.theguardian.com/business/2025/nov/18/buy-now-pay-later-klarna-ai-helped-halve-staff-boost-pay</link>
      <description>&lt;p&gt;Photograph: Robert Evans/AlamyKlarna says AI drive has helped halve staff numbers and boost payBuy now, pay later firm says pay has risen by 60% with staff numbers mostly cut by attrition and tech investmentKlarna has claimed that AI-related savings have allowed the buy now, pay later company to increase staff salaries by nearly 60%, but hinted it could slash more jobs after nearly halving its workforce over the past three years. He explained that Klarna has not hired “for a few years”. Explore more on these topicsBuy now, pay laterJob lossesFintechArtificial intelligence (AI)ComputingnewsShareReuse this content.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=45978739"&gt;&lt;strong&gt;HN Discussion&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href='https://www.theguardian.com/business/2025/nov/18/buy-now-pay-later-klarna-ai-helped-halve-staff-boost-pay'&gt;Read Original Article&lt;/a&gt;&lt;/p&gt;</description>
      <guid isPermaLink="true">https://www.theguardian.com/business/2025/nov/18/buy-now-pay-later-klarna-ai-helped-halve-staff-boost-pay</guid>
      <pubDate>Wed, 19 Nov 2025 12:25:12 +0000</pubDate>
      <comments>https://news.ycombinator.com/item?id=45978739</comments>
    </item>
  </channel>
</rss>
